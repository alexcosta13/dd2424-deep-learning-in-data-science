{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DD2424 Deep Learning in Data Science\n",
    "##Â Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/site-packages (3.4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/site-packages (4.60.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data import *\n",
    "from utils import *\n",
    "from layers.model import Model\n",
    "from layers.activations import ReLU, Softmax\n",
    "from layers.dense import Dense\n",
    "from layers.batchnormalization import BatchNormalization\n",
    "from layers.dropout import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, y = load_data('data_batch_1')\n",
    "X_mean = np.mean(X_train, axis=1).reshape(X_train.shape[0], 1)\n",
    "X_std = np.std(X_train, axis=1).reshape(X_train.shape[0], 1)\n",
    "X_train = normalize(X_train, X_mean, X_std)\n",
    "\n",
    "assert np.allclose(np.mean(X_train, axis=1).reshape(X_train.shape[0], 1), np.zeros((X_train.shape[0], 1))), \\\n",
    "    \"Check normalization, mean should be 0 \"\n",
    "assert np.allclose(np.std(X_train, axis=1).reshape(X_train.shape[0], 1), np.ones((X_train.shape[0], 1))), \\\n",
    "    \"Check normalization, std should be 1\"\n",
    "\n",
    "X_val, Y_val, _ = load_data('data_batch_2')\n",
    "X_test, Y_test, _ = load_data('test_batch')\n",
    "X_val = normalize(X_val, X_mean, X_std)\n",
    "X_test = normalize(X_test, X_mean, X_std)\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "batch = X_train[:, :BATCH_SIZE], Y_train[:, :BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Upgrade assignment 2 code to train & test k-layer networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-layer network\n",
    "Checking the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients, _ = classifier.compute_gradients(*batch, 0)\n",
    "gradients = list(reversed(gradients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_gradients_num, bias_gradients_num, _, _ = classifier.compute_gradients_num(*batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal = True\n",
    "threshold = 0\n",
    "\n",
    "for i, (grad_kernel, grad_bias) in enumerate(gradients):\n",
    "    grad_kernel_num = kernel_gradients_num[i]\n",
    "    grad_bias_num = bias_gradients_num[i]\n",
    "    \n",
    "    equal = equal and np.allclose(grad_kernel[:10, :], grad_kernel_num[:10, :], rtol=1e-6, atol=1e-6)\n",
    "    equal = equal and np.allclose(grad_bias, grad_bias_num, rtol=1e-6, atol=1e-6)\n",
    "    \n",
    "    threshold = max(threshold, np.max(np.abs(grad_kernel[:10, :] - grad_kernel_num[:10, :])))\n",
    "    threshold = max(threshold, np.max(np.abs(grad_bias - grad_bias_num)))\n",
    "\n",
    "print(equal)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three-layer network\n",
    "Checking the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients, _ = classifier.compute_gradients(*batch, 0)\n",
    "gradients = list(reversed(gradients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_gradients_num, bias_gradients_num, _, _ = classifier.compute_gradients_num(*batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal = True\n",
    "threshold = 0\n",
    "\n",
    "for i, (grad_kernel, grad_bias) in enumerate(gradients):\n",
    "    grad_kernel_num = kernel_gradients_num[i]\n",
    "    grad_bias_num = bias_gradients_num[i]\n",
    "    \n",
    "    equal = equal and np.allclose(grad_kernel[:10, :], grad_kernel_num[:10, :], rtol=1e-6, atol=1e-6)\n",
    "    equal = equal and np.allclose(grad_bias, grad_bias_num, rtol=1e-6, atol=1e-6)\n",
    "    \n",
    "    threshold = max(threshold, np.max(np.abs(grad_kernel[:10, :] - grad_kernel_num[:10, :])))\n",
    "    threshold = max(threshold, np.max(np.abs(grad_bias - grad_bias_num)))\n",
    "\n",
    "print(equal)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four-layer network\n",
    "Checking the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 30))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(30, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients, _ = classifier.compute_gradients(*batch, 0)\n",
    "gradients = list(reversed(gradients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_gradients_num, bias_gradients_num, _, _ = classifier.compute_gradients_num(*batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal = True\n",
    "threshold = 0\n",
    "\n",
    "for i, (grad_kernel, grad_bias) in enumerate(gradients):\n",
    "    grad_kernel_num = kernel_gradients_num[i]\n",
    "    grad_bias_num = bias_gradients_num[i]\n",
    "    \n",
    "    equal = equal and np.allclose(grad_kernel[:10, :], grad_kernel_num[:10, :], rtol=1e-6, atol=1e-6)\n",
    "    equal = equal and np.allclose(grad_bias, grad_bias_num, rtol=1e-6, atol=1e-6)\n",
    "    \n",
    "    threshold = max(threshold, np.max(np.abs(grad_kernel[:10, :] - grad_kernel_num[:10, :])))\n",
    "    threshold = max(threshold, np.max(np.abs(grad_bias - grad_bias_num)))\n",
    "\n",
    "print(equal)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Can I train multi-layer networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-layer network\n",
    "Replicate assignment 2 results (~46.66%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 500\n",
    "k = 3\n",
    "\n",
    "loss, accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, k=k, ns=ns, reg_lambda=0.01)\n",
    "\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steps = 2 * ns * k\n",
    "\n",
    "train_validation_error(*loss, label='loss', steps=steps)\n",
    "train_validation_error(*accuracy, label='accuracy', steps=steps)\n",
    "\n",
    "train_validation_error(*loss, label='loss', steps=steps, save='two-layer-basic')\n",
    "train_validation_error(*accuracy, label='accuracy', steps=steps, save='two-layer-basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the data for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, y = load_all_data()\n",
    "X_mean = np.mean(X_train, axis=1).reshape(X_train.shape[0], 1)\n",
    "X_std = np.std(X_train, axis=1).reshape(X_train.shape[0], 1)\n",
    "X_train = normalize(X_train, X_mean, X_std)\n",
    "\n",
    "assert np.allclose(np.mean(X_train, axis=1).reshape(X_train.shape[0], 1), np.zeros((X_train.shape[0], 1))), \\\n",
    "    \"Check normalization, mean should be 0 \"\n",
    "assert np.allclose(np.std(X_train, axis=1).reshape(X_train.shape[0], 1), np.ones((X_train.shape[0], 1))), \\\n",
    "    \"Check normalization, std should be 1\"\n",
    "\n",
    "X_val, Y_val, _ = load_all_data(validation=True)\n",
    "X_test, Y_test, _ = load_data('test_batch')\n",
    "X_val = normalize(X_val, X_mean, X_std)\n",
    "X_test = normalize(X_test, X_mean, X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggested hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 100\n",
    "eta_min = 1e-5\n",
    "eta_max = 1e-1\n",
    "lambda_ = 0.005\n",
    "k = 2\n",
    "ns = int(5 * 45_000 / n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 2 * ns * k\n",
    "\n",
    "train_validation_error(*loss, label='loss', steps=steps)\n",
    "train_validation_error(*accuracy, label='accuracy', steps=steps)\n",
    "\n",
    "train_validation_error(*loss, label='loss', steps=steps, save='three-layer-basic')\n",
    "train_validation_error(*accuracy, label='accuracy', steps=steps, save='three-layer-basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nine-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "# Layer 1\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(ReLU())\n",
    "# Layer 2\n",
    "classifier.add(Dense(50, 30))\n",
    "classifier.add(ReLU())\n",
    "# Layer 3\n",
    "classifier.add(Dense(30, 20))\n",
    "classifier.add(ReLU())\n",
    "# Layer 4\n",
    "classifier.add(Dense(20, 20))\n",
    "classifier.add(ReLU())\n",
    "# Layer 5\n",
    "classifier.add(Dense(20, 10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 6\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 7\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 8\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 9\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 2 * ns * k\n",
    "\n",
    "train_validation_error(*loss, label='loss', steps=steps)\n",
    "train_validation_error(*accuracy, label='accuracy', steps=steps)\n",
    "\n",
    "train_validation_error(*loss, label='loss', steps=steps, save='nine-layer-basic')\n",
    "train_validation_error(*accuracy, label='accuracy', steps=steps, save='nine-layer-basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Implement batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_gradients, batch_gradients = classifier.compute_gradients(*batch, 0)\n",
    "dense_gradients = list(reversed(dense_gradients))\n",
    "batch_gradients = list(reversed(batch_gradients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_gradients_num, bias_gradients_num, gamma_gradients_num, beta_gradients_num = classifier.compute_gradients_num(*batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal = True\n",
    "threshold = 0\n",
    "\n",
    "for i, (grad_kernel, grad_bias) in enumerate(dense_gradients):\n",
    "    grad_kernel_num = kernel_gradients_num[i]\n",
    "    grad_bias_num = bias_gradients_num[i]\n",
    "    \n",
    "    equal = equal and np.allclose(grad_kernel[:10, :], grad_kernel_num[:10, :], rtol=1e-6, atol=1e-6)\n",
    "    equal = equal and np.allclose(grad_bias, grad_bias_num, rtol=1e-6, atol=1e-6)\n",
    "    \n",
    "    threshold = max(threshold, np.max(np.abs(grad_kernel[:10, :] - grad_kernel_num[:10, :])))\n",
    "    threshold = max(threshold, np.max(np.abs(grad_bias - grad_bias_num)))\n",
    "    \n",
    "for i, (grad_gamma, grad_beta) in enumerate(batch_gradients):\n",
    "    grad_gamma_num = gamma_gradients_num[i]\n",
    "    grad_beta_num = beta_gradients_num[i]\n",
    "    \n",
    "    equal = equal and np.allclose(grad_gamma, grad_gamma_num, rtol=1e-6, atol=1e-6)\n",
    "    equal = equal and np.allclose(grad_beta, grad_beta_num, rtol=1e-6, atol=1e-6)\n",
    "    \n",
    "    threshold = max(threshold, np.max(np.abs(grad_gamma - grad_gamma_num)))\n",
    "    threshold = max(threshold, np.max(np.abs(grad_beta - grad_beta_num)))\n",
    "\n",
    "print(equal)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 2 * ns * k\n",
    "train_validation_error(*loss, label='loss', steps=steps)\n",
    "train_validation_error(*accuracy, label='accuracy', steps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning lambda\n",
    "Coarse search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_lambda = [10 ** l for l in np.linspace(-5, -1, 5)]\n",
    "\n",
    "for i in reg_lambda:\n",
    "    classifier.initialize_weights()\n",
    "    classifier.fit(X_train, Y_train, k=k, ns=ns, reg_lambda=i)\n",
    "    print(f\"Accuracy for regularization lambda={i}: {classifier.accuracy(X_test, Y_test)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lambda = [10 ** l for l in np.linspace(-3, -1.5, 10)]\n",
    "\n",
    "for i in reg_lambda:\n",
    "    classifier.initialize_weights()\n",
    "    classifier.fit(X_train, Y_train, k=k, ns=ns, reg_lambda=i)\n",
    "    print(f\"Accuracy for regularization lambda={i}: {classifier.accuracy(X_test, Y_test)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nine-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "# Layer 1\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "# Layer 2\n",
    "classifier.add(Dense(50, 30))\n",
    "classifier.add(BatchNormalization(30))\n",
    "classifier.add(ReLU())\n",
    "# Layer 3\n",
    "classifier.add(Dense(30, 20))\n",
    "classifier.add(BatchNormalization(20))\n",
    "classifier.add(ReLU())\n",
    "# Layer 4\n",
    "classifier.add(Dense(20, 20))\n",
    "classifier.add(BatchNormalization(20))\n",
    "classifier.add(ReLU())\n",
    "# Layer 5\n",
    "classifier.add(Dense(20, 10))\n",
    "classifier.add(BatchNormalization(10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 6\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(BatchNormalization(10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 7\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(BatchNormalization(10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 8\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(BatchNormalization(10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 9\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 2 * ns * k\n",
    "train_validation_error(*loss, label='loss', steps=steps)\n",
    "train_validation_error(*accuracy, label='accuracy', steps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Three-layer network\n",
    "Include graphs of the evolution of the loss function when you train the 3-layer network with and without batch normalization with the given default parameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 100\n",
    "eta_min = 1e-5\n",
    "eta_max = 1e-1\n",
    "lambda_ = 0.005\n",
    "k = 2\n",
    "ns = int(5 * 45_000 / n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 2 * ns * k\n",
    "compare_batch_plot(*loss, *bn_loss, label='loss', steps=steps)\n",
    "compare_batch_plot(*accuracy, *bn_accuracy, label='accuracy', steps=steps)\n",
    "\n",
    "compare_batch_plot(*loss, *bn_loss, label='loss', steps=steps, save='three-layer-comparison')\n",
    "compare_batch_plot(*accuracy, *bn_accuracy, label='accuracy', steps=steps, save='three-layer-comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nine-layer network\n",
    "Include graphs of the evolution of the loss function when you train the 3-layer network with and without batch normalization with the given default parameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "# Layer 1\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(ReLU())\n",
    "# Layer 2\n",
    "classifier.add(Dense(50, 30))\n",
    "classifier.add(ReLU())\n",
    "# Layer 3\n",
    "classifier.add(Dense(30, 20))\n",
    "classifier.add(ReLU())\n",
    "# Layer 4\n",
    "classifier.add(Dense(20, 20))\n",
    "classifier.add(ReLU())\n",
    "# Layer 5\n",
    "classifier.add(Dense(20, 10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 6\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 7\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 8\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 9\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Model()\n",
    "# Layer 1\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "# Layer 2\n",
    "classifier.add(Dense(50, 30))\n",
    "classifier.add(BatchNormalization(30))\n",
    "classifier.add(ReLU())\n",
    "# Layer 3\n",
    "classifier.add(Dense(30, 20))\n",
    "classifier.add(BatchNormalization(20))\n",
    "classifier.add(ReLU())\n",
    "# Layer 4\n",
    "classifier.add(Dense(20, 20))\n",
    "classifier.add(BatchNormalization(20))\n",
    "classifier.add(ReLU())\n",
    "# Layer 5\n",
    "classifier.add(Dense(20, 10))\n",
    "classifier.add(BatchNormalization(10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 6\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(BatchNormalization(10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 7\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(BatchNormalization(10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 8\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(BatchNormalization(10))\n",
    "classifier.add(ReLU())\n",
    "# Layer 9\n",
    "classifier.add(Dense(10, 10))\n",
    "classifier.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [03:31<00:00, 11.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5158"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072 50\n",
      "50 30\n",
      "30 20\n",
      "20 20\n",
      "20 10\n",
      "10 10\n",
      "10 10\n",
      "10 10\n",
      "10 10\n"
     ]
    }
   ],
   "source": [
    "for layer in classifier.layers:\n",
    "    try:\n",
    "        print(layer.input_size, layer.output_size)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 2 * ns * k\n",
    "compare_batch_plot(*loss, *bn_loss, label='loss', steps=steps)\n",
    "compare_batch_plot(*accuracy, *bn_accuracy, label='accuracy', steps=steps)\n",
    "\n",
    "compare_batch_plot(*loss, *bn_loss, label='loss', steps=steps, save='nine-layer-comparison')\n",
    "compare_batch_plot(*accuracy, *bn_accuracy, label='accuracy', steps=steps, save='nine-layer-comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigma_list = [1e-1, 1e-3, 1e-4]\n",
    "\n",
    "for sigma in sigma_list:\n",
    "    classifier = Model()\n",
    "    classifier.add(Dense(X_train.shape[0], 50, initialization=\"normal\", initialization_sigma=sigma))\n",
    "    classifier.add(ReLU())\n",
    "    classifier.add(Dense(50, 50, initialization=\"normal\", initialization_sigma=sigma))\n",
    "    classifier.add(ReLU())\n",
    "    classifier.add(Dense(50, 10, initialization=\"normal\", initialization_sigma=sigma))\n",
    "    classifier.add(Softmax())\n",
    "    \n",
    "    loss, accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "    print(f\"Test accuracy for initialization sigma {sigma}, without batch normalization:\"\n",
    "          f\"{classifier.accuracy(X_test, Y_test)}\")\n",
    "    \n",
    "    classifier = Model()\n",
    "    classifier.add(Dense(X_train.shape[0], 50, initialization=\"normal\", initialization_sigma=sigma))\n",
    "    classifier.add(BatchNormalization(50))\n",
    "    classifier.add(ReLU())\n",
    "    classifier.add(Dense(50, 50, initialization=\"normal\", initialization_sigma=sigma))\n",
    "    classifier.add(BatchNormalization(50))\n",
    "    classifier.add(ReLU())\n",
    "    classifier.add(Dense(50, 10, initialization=\"normal\", initialization_sigma=sigma))\n",
    "    classifier.add(Softmax())\n",
    "    \n",
    "    bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "    print(f\"Test accuracy for initialization sigma {sigma}, batch normalization:\"\n",
    "          f\"{classifier.accuracy(X_test, Y_test)}\")\n",
    "    \n",
    "    steps = 2 * ns * k\n",
    "    compare_batch_plot(*loss, *bn_loss, label='loss', steps=steps)\n",
    "    compare_batch_plot(*accuracy, *bn_accuracy, label='accuracy', steps=steps)\n",
    "\n",
    "    compare_batch_plot(*loss, *bn_loss, label='loss', steps=steps, save=f'sigma-{sigma}'.replace('.', '_'))\n",
    "    compare_batch_plot(*accuracy, *bn_accuracy, label='accuracy', steps=steps, save=f'sigma-{sigma}'.replace('.', '_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 100\n",
    "eta_min = 1e-5\n",
    "eta_max = 1e-1\n",
    "lambda_ = 0.005\n",
    "k = 2\n",
    "ns = int(5 * 45_000 / n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture\n",
    "Ideally, we would perform a grid search; due to lack of resources, let's first explore the depth of the network and then the number of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of layers\n",
    "Let's first explore different number of layers with similar node structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:01<00:00,  6.77s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 2-layer network, in the form of [50, 10]: 0.5152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:02<00:00,  6.82s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 3-layer network, in the form of [50, 50, 10]: 0.5316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [01:56<00:00,  6.48s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 4-layer network, in the form of [50, 40, 20, 10]: 0.5377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:02<00:00,  6.79s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 5-layer network, in the form of [50, 30, 20, 20, 10]: 0.5295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:00<00:00,  6.72s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 6-layer network, in the form of [50, 30, 20, 20, 10, 10]: 0.5226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:14<00:00,  7.45s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 7-layer network, in the form of [50, 30, 20, 20, 10, 10, 10]: 0.5215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:49<00:00,  9.43s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 8-layer network, in the form of [50, 30, 30, 20, 10, 10, 10, 10]: 0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:49<00:00,  9.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 9-layer network, in the form of [50, 30, 30, 20, 10, 10, 10, 10, 10]: 0.5138\n"
     ]
    }
   ],
   "source": [
    "architectures = [[50, 10],                                # 2-layer\n",
    "                 [50, 50, 10],                            # 3-layer\n",
    "                 [50, 40, 20, 10],                        # 4-layer\n",
    "                 [50, 30, 20, 20, 10],                    # 5-layer\n",
    "                 [50, 30, 20, 20, 10, 10],                # 6-layer\n",
    "                 [50, 30, 20, 20, 10, 10, 10],            # 7-layer\n",
    "                 [50, 30, 30, 20, 10, 10, 10, 10],        # 8-layer\n",
    "                 [50, 30, 30, 20, 10, 10, 10, 10, 10]]    # 9-layer\n",
    "\n",
    "for layers in architectures:\n",
    "    classifier = Model()\n",
    "\n",
    "    for i in range(len(layers) - 1):\n",
    "        classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "        classifier.add(BatchNormalization(layers[i]))\n",
    "        classifier.add(ReLU())\n",
    "\n",
    "    classifier.add(Dense(layers[-2], layers[-1]))\n",
    "    classifier.add(Softmax())\n",
    "\n",
    "    bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "\n",
    "    print(f\"Test accuracy for a {len(layers)}-layer network, in the form of {layers}: \"\n",
    "          f\"{classifier.accuracy(X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of nodes\n",
    "Let's now try different node configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [03:53<00:00, 12.98s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 4-layer network, in the form of [100, 50, 30, 10]: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:34<00:00,  8.60s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 4-layer network, in the form of [50, 50, 50, 10]: 0.5378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [03:51<00:00, 12.86s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 4-layer network, in the form of [100, 100, 10, 10]: 0.5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:46<00:00,  9.24s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 4-layer network, in the form of [30, 50, 100, 10]: 0.5231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:06<00:00,  7.03s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 4-layer network, in the form of [10, 100, 50, 10]: 0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:56<00:00,  9.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for a 4-layer network, in the form of [50, 150, 50, 10]: 0.55\n"
     ]
    }
   ],
   "source": [
    "architectures = [[100,  50,  30, 10],                        # 314000 weights, 190 nodes -- 55.23% accuracy\n",
    "                 [ 50,  40,  20, 10],                        # 156600 weights, 120 nodes -- 53.77% accuracy\n",
    "                 [ 50,  50,  50, 10],                        # 159100 weights, 160 nodes -- 53.78% accuracy\n",
    "                 [100, 100,  10, 10],                        # 318300 weights, 220 nodes -- 55.06% accuracy\n",
    "                 [ 30,  50, 100, 10],                        #  99660 weights, 190 nodes -- 52.31% accuracy\n",
    "                 [ 10, 100,  50, 10],                        #  37220 weights, 170 nodes -- 47.80% accuracy\n",
    "                 [ 50, 150,  50, 10]]                        # 169100 weights, 260 nodes -- 55.00% accuracy\n",
    "\n",
    "\n",
    "for layers in architectures:\n",
    "    classifier = Model()\n",
    "\n",
    "    for i in range(len(layers) - 1):\n",
    "        classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "        classifier.add(BatchNormalization(layers[i]))\n",
    "        classifier.add(ReLU())\n",
    "\n",
    "    classifier.add(Dense(layers[-2], layers[-1]))\n",
    "    classifier.add(Softmax())\n",
    "\n",
    "    bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "\n",
    "    print(f\"Test accuracy for a {len(layers)}-layer network, in the form of {layers}: \"\n",
    "          f\"{classifier.accuracy(X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply activation before BN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Three-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:08<00:00,  7.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5316"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:51<00:00,  9.53s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5296"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nine-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:40<00:00,  8.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5158"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [50, 30, 20, 20, 10, 10, 10, 10, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    \n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [03:04<00:00, 10.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5199"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [50, 30, 20, 20, 10, 10, 10, 10, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    \n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [04:38<00:00, 15.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5523"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [100,  50,  30, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    \n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [03:55<00:00, 13.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5475"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [100,  50,  30, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    \n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Three-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [02:01<00:00,  6.73s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5316"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 18/18 [03:53<00:00, 12.97s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4375"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|âââââ     | 26/55 [07:42<06:49, 14.13s/it]"
     ]
    }
   ],
   "source": [
    "classifier = Model()\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(X_train.shape[0], 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(50, 50))\n",
    "classifier.add(BatchNormalization(50))\n",
    "classifier.add(ReLU())\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(50, 10))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=3*k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nine-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [50, 30, 20, 20, 10, 10, 10, 10, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    \n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [50, 30, 20, 20, 10, 10, 10, 10, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dropout(0.5))\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    \n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [50, 30, 20, 20, 10, 10, 10, 10, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dropout(0.5))\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    \n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=3*k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [100,  50,  30, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    \n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [100,  50,  30, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dropout(0.5))\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    \n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [100,  50,  30, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dropout(0.5))\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    \n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=3*k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wider network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [200, 100,  60, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dropout(0.5))\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    \n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [200, 100,  60, 10]\n",
    "\n",
    "classifier = Model()\n",
    "\n",
    "for i in range(len(layers) - 1):\n",
    "    classifier.add(Dropout(0.5))\n",
    "    classifier.add(Dense(layers[i - 1] if i > 0 else X_train.shape[0], layers[i]))\n",
    "    classifier.add(BatchNormalization(layers[i]))\n",
    "    classifier.add(ReLU())\n",
    "    \n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(layers[-2], layers[-1]))\n",
    "classifier.add(Softmax())\n",
    "\n",
    "bn_loss, bn_accuracy = classifier.fit(X_train, Y_train, X_val, Y_val, ns=ns, k=3*k, reg_lambda=lambda_)\n",
    "classifier.accuracy(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
