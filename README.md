# dd2424-deep-learning-in-data-science
 
## Assignment 1
The first assignment trains and tests a **one-layer** network with multiple outputs to classify images from the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. The network is trained using mini-batch gradient descent applied to a cost function that computes the cross-entropy loss of the classifier applied to the labelled training data and an L<sub>2</sub> regularization term on the weight matrix.

## Assignment 2
The second assignment trains and tests a **two-layer** network with multiple outputs to classify images from the CIFAR-10 dataset. The network is trained using mini-batch gradient descent applied to a cost function that computes the cross-entropy loss of the classifier applied to the labelled training data and an L<sub>2</sub> regularization term on the weight matrix.

## Assignment 3
This assignment trains and tests a **k-layer** network with multiple outputs to classify images from the CIFAR-10 dataset. The network is trained using mini-batch gradient descent applied to a cost function that computes the cross-entropy loss of the classifier applied to the labelled training data and an L<sub>2</sub> regularization term on the weight matrix. The network uses cyclical learning rate for training and batch normalization.

## Assignment 4
This assignment trains an RNN to synthesize English text character by character. A vanilla RNN is trained using the text from the book *The Goblet of Fire* by J.K. Rowling. A variation of SGD is used for the optimization: AdaGrad.
